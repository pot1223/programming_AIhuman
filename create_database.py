# create_database.py (PowerPoint íŒŒì¼ìš©)

import os
from dotenv import load_dotenv
from langchain_community.document_loaders import UnstructuredPowerPointLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# 0. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- â— ì¤‘ìš”: ì•„ë˜ ì„¤ì •ë“¤ì„ ë³¸ì¸ì˜ í™˜ê²½ì— ë§ê²Œ í™•ì¸í•˜ì„¸ìš” ---

# 1. ì›ë³¸ ë°ì´í„°ê°€ ìˆëŠ” í´ë” ê²½ë¡œ ì„¤ì •
SOURCE_DIRECTORY_PATH = "./data" 

# 2. ChromaDBë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ ì„¤ì •
PERSIST_DIRECTORY = "/data/chroma" 

# 3. DB ì»¬ë ‰ì…˜ ì´ë¦„ ì„¤ì • (views.pyì™€ ë°˜ë“œì‹œ ë™ì¼í•´ì•¼ í•¨)
COLLECTION_NAME = "AIhuman-programming-3-14"

# 4. ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì„¤ì • (.env íŒŒì¼ê³¼ ë™ì¼í•˜ê²Œ)
EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-large")

# ----------------------------------------------------------------

def main():
    print("--- ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤ (PPTX íŒŒì¼ìš©) ---")
    
    all_documents = []

    # 1ë‹¨ê³„: ì§€ì •ëœ í´ë”ì—ì„œ ëª¨ë“  PPTX íŒŒì¼ ë¡œë“œ (Load)
    print(f"1ë‹¨ê³„: '{SOURCE_DIRECTORY_PATH}' í´ë”ì—ì„œ ëª¨ë“  PPTX íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    if not os.path.exists(SOURCE_DIRECTORY_PATH):
        print(f"ğŸš¨ ì˜¤ë¥˜: '{SOURCE_DIRECTORY_PATH}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í´ë” ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ ìˆœíšŒ
    for filename in os.listdir(SOURCE_DIRECTORY_PATH):
        if filename.endswith(".pptx"):
            file_path = os.path.join(SOURCE_DIRECTORY_PATH, filename)
            try:
                print(f"  - '{filename}' íŒŒì¼ ë¡œë”© ì¤‘...")
                loader = UnstructuredPowerPointLoader(file_path)
                # loader.load()ëŠ” ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ extend ì‚¬ìš©
                all_documents.extend(loader.load())
            except Exception as e:
                print(f"ğŸš¨ ì˜¤ë¥˜: '{filename}' íŒŒì¼ ë¡œë“œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
                continue # ë¬¸ì œê°€ ìˆëŠ” íŒŒì¼ì€ ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰

    if not all_documents:
        print("ğŸš¨ ì˜¤ë¥˜: ë¡œë“œí•  PPTX íŒŒì¼ì´ ì—†ê±°ë‚˜ ëª¨ë“  íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    print(f"ì„±ê³µ! ì´ {len(all_documents)}ê°œì˜ ìŠ¬ë¼ì´ë“œ/ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")


    # 2ë‹¨ê³„: ë¬¸ì„œ ë¶„í•  (Split)
    print("\n2ë‹¨ê³„: ë¡œë“œëœ ë¬¸ì„œë¥¼ ì²­í¬(chunk) ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(all_documents)
    print(f"ì„±ê³µ! ë¬¸ì„œë¥¼ ì´ {len(split_docs)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")

    # 3ë‹¨ê³„: ì„ë² ë”© ë° DB ì €ì¥ (Embed & Store)
    print("\n3ë‹¨ê³„: ë¶„í• ëœ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ì—¬ ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤...")
    try:
        embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
        
        # ê¸°ì¡´ DBê°€ ìˆë‹¤ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„± (ì„ íƒì‚¬í•­)
        if os.path.exists(PERSIST_DIRECTORY):
            print(f"  - ê¸°ì¡´ '{PERSIST_DIRECTORY}' í´ë”ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
            import shutil
            shutil.rmtree(PERSIST_DIRECTORY)

        vectordb = Chroma.from_documents(
            documents=split_docs, 
            embedding=embeddings, 
            persist_directory=PERSIST_DIRECTORY,
            collection_name=COLLECTION_NAME
        )
        print("ì„±ê³µ! ë°ì´í„°ë² ì´ìŠ¤ì— ëª¨ë“  ì²­í¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ ì˜¤ë¥˜: ì„ë² ë”© ë˜ëŠ” DB ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. ì˜¤ë¥˜: {e}")
        return
        
    # 4ë‹¨ê³„: ìµœì¢… ê²€ì¦
    count = vectordb._collection.count()
    print(f"\n--- âœ… ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ ---")
    print(f"ì €ì¥ëœ í´ë”: '{PERSIST_DIRECTORY}'")
    print(f"ì»¬ë ‰ì…˜ ì´ë¦„: '{COLLECTION_NAME}'")
    print(f"ì €ì¥ëœ ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: {count}")


if __name__ == "__main__":
    main()